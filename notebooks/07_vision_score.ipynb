{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# [7] 視界スコア指標 - Phase 5\n\nward座標データからグリッド特徴量を生成し、勝敗予測モデルを学習します。\n\n## 処理フロー\n1. **Task A**: グリッド特徴量生成（wards_matched.csv → ward_grid.npz）\n2. **Task B**: データセット構築（ward_grid.npz + 勝敗ラベル → vision_dataset.npz）\n3. **Task C**: 予測モデル学習（ロジスティック回帰 / CNN）\n4. **Task D**: ヒートマップ可視化\n\n## 前提条件\n- **06_ward_batch_processing.ipynb 完了**（wards_matched.csvが各試合フォルダに存在）\n- タイムラインデータ（data/timeline/*.json）"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-1: ライブラリインポート\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path(r\"c:\\Users\\lapis\\Desktop\\LoL_WorkSp_win\\pyLoL-_WorkSp\\pyLoL-v2\")\n",
    "\n",
    "# autoLeagueモジュール\n",
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from autoLeague.scoring import (\n",
    "    DatasetBuilder,\n",
    "    build_dataset,\n",
    "    VisionPredictor,\n",
    "    load_dataset,\n",
    "    visualize_importance_heatmap,\n",
    "    visualize_importance_grid,\n",
    "    visualize_top_cells,\n",
    "    print_importance_summary,\n",
    ")\n",
    "\n",
    "print(\"インポート完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-2: パス設定\n",
    "\n",
    "# 入力データ\n",
    "DATASET_DIR = Path(r\"C:\\dataset_20260105\")  # ミニマップキャプチャ + wards_matched.csv\n",
    "TIMELINE_DIR = PROJECT_ROOT / \"data\" / \"timeline\"  # タイムラインJSON\n",
    "\n",
    "# 出力\n",
    "OUTPUT_DATASET = PROJECT_ROOT / \"data\" / \"vision_dataset.npz\"\n",
    "OUTPUT_MODEL_DIR = PROJECT_ROOT / \"models\"\n",
    "OUTPUT_HEATMAP_DIR = PROJECT_ROOT / \"heatmaps\"\n",
    "\n",
    "# 確認\n",
    "print(f\"データセットディレクトリ: {DATASET_DIR}\")\n",
    "print(f\"  存在: {DATASET_DIR.exists()}\")\n",
    "\n",
    "if DATASET_DIR.exists():\n",
    "    match_dirs = sorted(DATASET_DIR.glob(\"JP1-*\"))\n",
    "    print(f\"  試合数: {len(match_dirs)}\")\n",
    "\n",
    "print(f\"\\nタイムラインディレクトリ: {TIMELINE_DIR}\")\n",
    "print(f\"  存在: {TIMELINE_DIR.exists()}\")\n",
    "\n",
    "if TIMELINE_DIR.exists():\n",
    "    timeline_files = list(TIMELINE_DIR.glob(\"JP1_*.json\"))\n",
    "    print(f\"  ファイル数: {len(timeline_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A + B: データセット構築\n",
    "\n",
    "各試合の`wards_matched.csv`からグリッド特徴量を生成し、勝敗ラベルを付与して統合データセットを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-3: wards_matched.csvの確認\n",
    "\n",
    "# 最初の試合のwards_matched.csvを確認\n",
    "if DATASET_DIR.exists():\n",
    "    match_dirs = sorted(DATASET_DIR.glob(\"JP1-*\"))\n",
    "    if match_dirs:\n",
    "        sample_csv = match_dirs[0] / \"wards_matched.csv\"\n",
    "        if sample_csv.exists():\n",
    "            df = pd.read_csv(sample_csv)\n",
    "            print(f\"サンプル: {sample_csv}\")\n",
    "            print(f\"レコード数: {len(df)}\")\n",
    "            print(f\"\\nカラム: {list(df.columns)}\")\n",
    "            print(f\"\\n先頭5行:\")\n",
    "            display(df.head())\n",
    "        else:\n",
    "            print(f\"wards_matched.csvが見つかりません: {sample_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-4: データセット構築（Task A + B）\n",
    "\n",
    "# DatasetBuilderを使用\n",
    "builder = DatasetBuilder(\n",
    "    dataset_dir=DATASET_DIR,\n",
    "    timeline_dir=TIMELINE_DIR,\n",
    ")\n",
    "\n",
    "# 全試合を処理\n",
    "print(\"データセット構築開始...\")\n",
    "X, y, match_ids = builder.build()\n",
    "\n",
    "print(f\"\\n=== データセット情報 ===\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"試合数: {len(match_ids)}\")\n",
    "print(f\"Blue勝利: {y.sum()}, Red勝利: {len(y) - y.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-5: データセット保存\n",
    "\n",
    "# 出力ディレクトリ作成\n",
    "OUTPUT_DATASET.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 保存\n",
    "np.savez(\n",
    "    OUTPUT_DATASET,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    match_ids=np.array(match_ids, dtype=object)\n",
    ")\n",
    "\n",
    "print(f\"データセット保存完了: {OUTPUT_DATASET}\")\n",
    "print(f\"ファイルサイズ: {OUTPUT_DATASET.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: 予測モデル学習\n",
    "\n",
    "グリッド特徴量から勝敗を予測するモデルを学習します。\n",
    "\n",
    "### モデル選択肢\n",
    "1. **ロジスティック回帰**（推奨）: シンプルで解釈しやすい\n",
    "2. **浅いCNN**: 空間パターンを学習可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-6: データセット読み込み（既存データを使用する場合）\n",
    "\n",
    "# 既にvision_dataset.npzがある場合はここから開始可能\n",
    "if OUTPUT_DATASET.exists():\n",
    "    X, y, match_ids = load_dataset(OUTPUT_DATASET)\n",
    "    print(f\"データセット読み込み完了\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"Blue勝利: {y.sum()}, Red勝利: {len(y) - y.sum()}\")\n",
    "else:\n",
    "    print(f\"データセットが見つかりません: {OUTPUT_DATASET}\")\n",
    "    print(\"cell-4, cell-5を先に実行してください\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-7: Train/Test分割\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y\n",
    "    )\n",
    "except ValueError:\n",
    "    # サンプル数が少ない場合は層化なし\n",
    "    print(\"警告: サンプル数が少ないため層化抽出を無効化\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(f\"学習データ: {len(X_train)}件\")\n",
    "print(f\"テストデータ: {len(X_test)}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-8: ロジスティック回帰モデルの学習\n",
    "\n",
    "# モデル作成\n",
    "predictor_lr = VisionPredictor(model_type=\"logistic\")\n",
    "\n",
    "# 学習\n",
    "print(\"ロジスティック回帰モデル学習中...\")\n",
    "metrics_lr = predictor_lr.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "print(f\"\\n学習完了\")\n",
    "print(f\"Train accuracy: {metrics_lr['train_accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-9: ロジスティック回帰モデルの評価\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 予測\n",
    "y_pred_lr = predictor_lr.predict(X_test)\n",
    "\n",
    "# 評価\n",
    "print(\"=== ロジスティック回帰 評価結果 ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_lr):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr, zero_division=0):.3f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_lr, zero_division=0):.3f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_lr, zero_division=0):.3f}\")\n",
    "\n",
    "# 混同行列\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(f\"\\n混同行列:\")\n",
    "print(f\"(予測→)   Red  Blue\")\n",
    "print(f\"実際Red   {cm[0][0]:4d}  {cm[0][1]:4d}\")\n",
    "print(f\"実際Blue  {cm[1][0]:4d}  {cm[1][1]:4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-10: CNNモデルの学習（オプション）\n",
    "\n",
    "# CNNモデル作成\n",
    "predictor_cnn = VisionPredictor(model_type=\"cnn\")\n",
    "\n",
    "# 学習\n",
    "print(\"CNNモデル学習中...\")\n",
    "metrics_cnn = predictor_cnn.fit(X_train, y_train, epochs=100, verbose=True)\n",
    "\n",
    "# 予測\n",
    "y_pred_cnn = predictor_cnn.predict(X_test)\n",
    "\n",
    "# 評価\n",
    "print(\"\\n=== CNN 評価結果 ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_cnn):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_cnn, zero_division=0):.3f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_cnn, zero_division=0):.3f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_cnn, zero_division=0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-11: モデル比較\n",
    "\n",
    "print(\"=== モデル比較 ===\")\n",
    "print(f\"{'モデル':<20} {'Accuracy':<12} {'F1 Score':<12}\")\n",
    "print(\"-\" * 44)\n",
    "print(f\"{'ロジスティック回帰':<20} {accuracy_score(y_test, y_pred_lr):<12.3f} {f1_score(y_test, y_pred_lr, zero_division=0):<12.3f}\")\n",
    "print(f\"{'CNN':<20} {accuracy_score(y_test, y_pred_cnn):<12.3f} {f1_score(y_test, y_pred_cnn, zero_division=0):<12.3f}\")\n",
    "print(f\"{'ベースライン(ランダム)':<20} {'0.500':<12} {'-':<12}\")\n",
    "\n",
    "# 推奨モデル選択\n",
    "if accuracy_score(y_test, y_pred_lr) >= accuracy_score(y_test, y_pred_cnn):\n",
    "    best_model = \"logistic\"\n",
    "    best_predictor = predictor_lr\n",
    "else:\n",
    "    best_model = \"cnn\"\n",
    "    best_predictor = predictor_cnn\n",
    "\n",
    "print(f\"\\n推奨モデル: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-12: モデル保存\n",
    "\n",
    "OUTPUT_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ロジスティック回帰モデル保存\n",
    "lr_path = OUTPUT_MODEL_DIR / \"vision_predictor.joblib\"\n",
    "predictor_lr.save(lr_path)\n",
    "print(f\"ロジスティック回帰モデル保存: {lr_path}\")\n",
    "\n",
    "# CNNモデル保存\n",
    "cnn_path = OUTPUT_MODEL_DIR / \"vision_predictor.pt\"\n",
    "predictor_cnn.save(cnn_path)\n",
    "print(f\"CNNモデル保存: {cnn_path}\")\n",
    "\n",
    "# メトリクス保存\n",
    "metrics_path = OUTPUT_MODEL_DIR / \"vision_predictor_metrics.json\"\n",
    "metrics = {\n",
    "    \"model_type\": best_model,\n",
    "    \"n_samples_train\": len(X_train),\n",
    "    \"n_samples_test\": len(X_test),\n",
    "    \"test_accuracy\": float(accuracy_score(y_test, y_pred_lr if best_model == \"logistic\" else y_pred_cnn)),\n",
    "    \"test_precision\": float(precision_score(y_test, y_pred_lr if best_model == \"logistic\" else y_pred_cnn, zero_division=0)),\n",
    "    \"test_recall\": float(recall_score(y_test, y_pred_lr if best_model == \"logistic\" else y_pred_cnn, zero_division=0)),\n",
    "    \"test_f1\": float(f1_score(y_test, y_pred_lr if best_model == \"logistic\" else y_pred_cnn, zero_division=0)),\n",
    "}\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"メトリクス保存: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D: ヒートマップ可視化\n",
    "\n",
    "特徴量重要度をヒートマップとして可視化し、「どの座標・時間帯のward配置が勝敗に影響するか」を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-13: 特徴量重要度取得\n",
    "\n",
    "# ロジスティック回帰の重要度を使用（解釈しやすい）\n",
    "importance = predictor_lr.get_feature_importance()\n",
    "\n",
    "print(f\"特徴量重要度\")\n",
    "print(f\"  形状: {importance.shape}\")\n",
    "print(f\"  値域: [{importance.min():.4f}, {importance.max():.4f}]\")\n",
    "\n",
    "# 統計情報表示\n",
    "print_importance_summary(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-14: 特徴量重要度保存\n",
    "\n",
    "importance_path = OUTPUT_MODEL_DIR / \"vision_importance.npy\"\n",
    "np.save(importance_path, importance)\n",
    "print(f\"特徴量重要度保存: {importance_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-15: 時間帯別ヒートマップ生成\n",
    "\n",
    "OUTPUT_HEATMAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ヒートマップ生成\n",
    "output_files = visualize_importance_heatmap(\n",
    "    importance=importance,\n",
    "    output_dir=OUTPUT_HEATMAP_DIR,\n",
    ")\n",
    "\n",
    "print(f\"生成されたファイル:\")\n",
    "for f in output_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-16: グリッド表示（3時間帯並列）\n",
    "\n",
    "grid_path = visualize_importance_grid(\n",
    "    importance=importance,\n",
    "    output_path=OUTPUT_HEATMAP_DIR / \"importance_grid.png\",\n",
    ")\n",
    "\n",
    "# 表示\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=str(grid_path), width=900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-17: 上位セルハイライト表示\n",
    "\n",
    "top_cells_path = visualize_top_cells(\n",
    "    importance=importance,\n",
    "    output_path=OUTPUT_HEATMAP_DIR / \"importance_top_cells.png\",\n",
    "    top_n=10,\n",
    ")\n",
    "\n",
    "# 表示\n",
    "display(Image(filename=str(top_cells_path), width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-18: 統合ヒートマップ表示\n",
    "\n",
    "combined_path = OUTPUT_HEATMAP_DIR / \"importance_combined.png\"\n",
    "if combined_path.exists():\n",
    "    display(Image(filename=str(combined_path), width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-19: 結果サマリー\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Phase 5 視界スコア指標 - 完了\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n【データセット】\")\n",
    "print(f\"  試合数: {len(match_ids)}\")\n",
    "print(f\"  入力形状: {X.shape}\")\n",
    "print(f\"  Blue勝利: {y.sum()}, Red勝利: {len(y) - y.sum()}\")\n",
    "\n",
    "print(f\"\\n【モデル性能】\")\n",
    "print(f\"  推奨モデル: {best_model}\")\n",
    "print(f\"  Test Accuracy: {metrics['test_accuracy']:.1%}\")\n",
    "print(f\"  Test F1 Score: {metrics['test_f1']:.1%}\")\n",
    "print(f\"  ベースライン改善: +{(metrics['test_accuracy'] - 0.5) / 0.5 * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n【出力ファイル】\")\n",
    "print(f\"  データセット: {OUTPUT_DATASET}\")\n",
    "print(f\"  モデル: {lr_path}\")\n",
    "print(f\"  メトリクス: {metrics_path}\")\n",
    "print(f\"  ヒートマップ: {OUTPUT_HEATMAP_DIR}/\")\n",
    "\n",
    "print(f\"\\n【主要な知見】\")\n",
    "phase_totals = [np.abs(importance[i]).sum() for i in range(3)]\n",
    "most_important_phase = np.argmax(phase_totals)\n",
    "phase_names = [\"Phase 1 (0-10min)\", \"Phase 2 (10-20min)\", \"Phase 3 (20min+)\"]\n",
    "print(f\"  最重要時間帯: {phase_names[most_important_phase]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}