{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# [6] Wardバッチ処理 - Google Colab版\n",
    "\n",
    "A100 GPUを使用して高速にward検出を実行します。\n",
    "\n",
    "## 事前準備（ローカルPC）\n",
    "Google Driveに以下をアップロード:\n",
    "1. `models/best.pt` -> `MyDrive/pyLoL/models/best.pt`\n",
    "2. `C:\\dataset_20260105` -> `MyDrive/pyLoL/dataset_20260105/` (フォルダごと)\n",
    "3. `data/timeline/` -> `MyDrive/pyLoL/timeline/`\n",
    "\n",
    "## 処理フロー\n",
    "1. **YOLO推論**: GPUバッチ推論（BATCH_SIZE=64）\n",
    "2. **クラスタリング**: 同一wardをグループ化\n",
    "3. **タイムライン統合**: Riot APIのwardイベントとマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-1: 環境セットアップ\n",
    "# Driveマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ultralytics インストール\n",
    "!pip install -q ultralytics\n",
    "\n",
    "# GPU確認\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-2: インポート + 設定\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# === Google Drive パス設定 ===\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive/pyLoL\")\n",
    "MODEL_PATH = DRIVE_ROOT / \"models\" / \"best.pt\"\n",
    "DATASET_DIR = DRIVE_ROOT / \"dataset_20260105\"\n",
    "TIMELINE_DIR = DRIVE_ROOT / \"timeline\"\n",
    "\n",
    "# === 推論設定 ===\n",
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "IMAGE_SIZE = 512\n",
    "BATCH_SIZE = 64  # A100用（40GB VRAM）\n",
    "\n",
    "# === クラスタリング設定 ===\n",
    "DISTANCE_THRESHOLD = 0.01\n",
    "MIN_FRAMES = 3\n",
    "GAP_TOLERANCE = 10\n",
    "\n",
    "# === タイムライン統合設定 ===\n",
    "FRAME_TOLERANCE = 10\n",
    "DEFAULT_MS_PER_FRAME = 376\n",
    "MIN_CONFIDENCE_DETECTION_ONLY = 0.5\n",
    "RIVER_SIGHT_POSITIONS = [(362, 332), (151, 178)]\n",
    "RIVER_SIGHT_RADIUS = 10\n",
    "RIVER_SIGHT_DURATION_MIN_MS = 75000\n",
    "RIVER_SIGHT_DURATION_MAX_MS = 93000\n",
    "\n",
    "# パス確認\n",
    "print(f\"モデル: {MODEL_PATH}\")\n",
    "print(f\"  存在: {MODEL_PATH.exists()}\")\n",
    "print(f\"\\nデータセット: {DATASET_DIR}\")\n",
    "print(f\"  存在: {DATASET_DIR.exists()}\")\n",
    "if DATASET_DIR.exists():\n",
    "    match_dirs = sorted(DATASET_DIR.glob(\"JP1-*\"))\n",
    "    print(f\"  試合数: {len(match_dirs)}\")\n",
    "print(f\"\\nタイムライン: {TIMELINE_DIR}\")\n",
    "print(f\"  存在: {TIMELINE_DIR.exists()}\")\n",
    "\n",
    "# GPU確認\n",
    "if torch.cuda.is_available():\n",
    "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {vram_gb:.1f} GB\")\n",
    "    print(f\"バッチサイズ: {BATCH_SIZE}\")\n",
    "else:\n",
    "    print(\"\\n警告: GPUが利用できません\")\n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "# モデル読み込み\n",
    "model = YOLO(str(MODEL_PATH))\n",
    "print(f\"\\nモデル読み込み完了\")\n",
    "print(f\"クラス: {model.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-3: データ構造 + 関数定義\n",
    "\n",
    "# === データ構造 ===\n",
    "@dataclass\n",
    "class Detection:\n",
    "    frame: int\n",
    "    class_id: int\n",
    "    class_name: str\n",
    "    x: float\n",
    "    y: float\n",
    "    w: float\n",
    "    h: float\n",
    "    confidence: float\n",
    "\n",
    "@dataclass\n",
    "class Ward:\n",
    "    ward_id: int\n",
    "    class_id: int\n",
    "    class_name: str\n",
    "    x: float\n",
    "    y: float\n",
    "    frame_start: int\n",
    "    frame_end: int\n",
    "    detections: List[Detection] = field(default_factory=list)\n",
    "    matched: bool = False\n",
    "    timeline_ward_id: Optional[int] = None\n",
    "\n",
    "    @property\n",
    "    def confidence_avg(self) -> float:\n",
    "        return sum(d.confidence for d in self.detections) / len(self.detections) if self.detections else 0.0\n",
    "\n",
    "    @property\n",
    "    def detection_count(self) -> int:\n",
    "        return len(self.detections)\n",
    "\n",
    "    @property\n",
    "    def team(self) -> str:\n",
    "        return \"red\" if \"enemy\" in self.class_name else \"blue\"\n",
    "\n",
    "    @property\n",
    "    def is_stealth_ward(self) -> bool:\n",
    "        return \"stealth_ward\" in self.class_name\n",
    "\n",
    "    @property\n",
    "    def is_control_ward(self) -> bool:\n",
    "        return \"control_ward\" in self.class_name\n",
    "\n",
    "    @property\n",
    "    def x_pixel(self) -> int:\n",
    "        return int(self.x * 512)\n",
    "\n",
    "    @property\n",
    "    def y_pixel(self) -> int:\n",
    "        return int(self.y * 512)\n",
    "\n",
    "@dataclass\n",
    "class TimelineWardEvent:\n",
    "    timeline_ward_id: int\n",
    "    event_type: str\n",
    "    timestamp: int\n",
    "    ward_type: str\n",
    "    participant_id: int\n",
    "    team: str\n",
    "    frame_expected: int\n",
    "\n",
    "    @property\n",
    "    def is_stealth_ward(self) -> bool:\n",
    "        return self.ward_type in (\"YELLOW_TRINKET\", \"SIGHT_WARD\", \"BLUE_TRINKET\")\n",
    "\n",
    "    @property\n",
    "    def is_control_ward(self) -> bool:\n",
    "        return self.ward_type == \"CONTROL_WARD\"\n",
    "\n",
    "@dataclass\n",
    "class MatchedWard:\n",
    "    ward_id: int\n",
    "    timeline_ward_id: Optional[int]\n",
    "    class_name: str\n",
    "    ward_type: str\n",
    "    team: str\n",
    "    x_pixel: int\n",
    "    y_pixel: int\n",
    "    x_normalized: float\n",
    "    y_normalized: float\n",
    "    frame_start: int\n",
    "    frame_end: int\n",
    "    confidence_avg: float\n",
    "    creator_id: Optional[int]\n",
    "    timestamp_placed: Optional[int]\n",
    "    timestamp_killed: Optional[int]\n",
    "    match_status: str\n",
    "\n",
    "# === 推論関数 ===\n",
    "def run_inference(model, match_dir: Path, conf: float = CONFIDENCE_THRESHOLD,\n",
    "                  batch_size: int = BATCH_SIZE) -> List[Detection]:\n",
    "    frame_dir = match_dir / \"0\"\n",
    "    if not frame_dir.exists():\n",
    "        return []\n",
    "\n",
    "    frame_files = sorted(frame_dir.glob(\"*.png\"), key=lambda p: int(p.stem))\n",
    "    if not frame_files:\n",
    "        return []\n",
    "\n",
    "    detections = []\n",
    "    for i in range(0, len(frame_files), batch_size):\n",
    "        batch_files = frame_files[i:i+batch_size]\n",
    "        batch_paths = [str(p) for p in batch_files]\n",
    "        frame_nums = [int(p.stem) for p in batch_files]\n",
    "\n",
    "        results = model(batch_paths, imgsz=IMAGE_SIZE, conf=conf, verbose=False)\n",
    "\n",
    "        for frame_num, result in zip(frame_nums, results):\n",
    "            for box in result.boxes:\n",
    "                detections.append(Detection(\n",
    "                    frame=frame_num,\n",
    "                    class_id=int(box.cls[0]),\n",
    "                    class_name=model.names[int(box.cls[0])],\n",
    "                    x=box.xywhn[0][0].item(),\n",
    "                    y=box.xywhn[0][1].item(),\n",
    "                    w=box.xywhn[0][2].item(),\n",
    "                    h=box.xywhn[0][3].item(),\n",
    "                    confidence=float(box.conf[0])\n",
    "                ))\n",
    "    return detections\n",
    "\n",
    "# === クラスタリング ===\n",
    "def cluster_detections(detections: List[Detection]) -> List[Ward]:\n",
    "    if not detections:\n",
    "        return []\n",
    "\n",
    "    sorted_detections = sorted(detections, key=lambda d: d.frame)\n",
    "    active_wards: Dict[int, List[Ward]] = defaultdict(list)\n",
    "    completed_wards = []\n",
    "    next_ward_id = 1\n",
    "\n",
    "    for det in sorted_detections:\n",
    "        matched = False\n",
    "        for ward in active_wards[det.class_id]:\n",
    "            dist = np.sqrt((det.x - ward.detections[-1].x)**2 + (det.y - ward.detections[-1].y)**2)\n",
    "            if dist < DISTANCE_THRESHOLD and det.frame - ward.frame_end <= GAP_TOLERANCE:\n",
    "                ward.detections.append(det)\n",
    "                ward.frame_end = det.frame\n",
    "                ward.x = sum(d.x for d in ward.detections) / len(ward.detections)\n",
    "                ward.y = sum(d.y for d in ward.detections) / len(ward.detections)\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            new_ward = Ward(\n",
    "                ward_id=next_ward_id, class_id=det.class_id, class_name=det.class_name,\n",
    "                x=det.x, y=det.y, frame_start=det.frame, frame_end=det.frame, detections=[det]\n",
    "            )\n",
    "            active_wards[det.class_id].append(new_ward)\n",
    "            next_ward_id += 1\n",
    "\n",
    "        for class_id in list(active_wards.keys()):\n",
    "            still_active = [w for w in active_wards[class_id] if det.frame - w.frame_end <= GAP_TOLERANCE]\n",
    "            completed_wards.extend([w for w in active_wards[class_id] if det.frame - w.frame_end > GAP_TOLERANCE])\n",
    "            active_wards[class_id] = still_active\n",
    "\n",
    "    for class_id in active_wards:\n",
    "        completed_wards.extend(active_wards[class_id])\n",
    "\n",
    "    filtered = [w for w in completed_wards if w.detection_count >= MIN_FRAMES]\n",
    "    for i, w in enumerate(sorted(filtered, key=lambda x: x.frame_start), 1):\n",
    "        w.ward_id = i\n",
    "    return sorted(filtered, key=lambda x: x.frame_start)\n",
    "\n",
    "# === 保存関数 ===\n",
    "def save_detections(detections: List[Detection], path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['frame', 'class_id', 'class_name', 'x', 'y', 'w', 'h', 'confidence'])\n",
    "        for d in detections:\n",
    "            writer.writerow([d.frame, d.class_id, d.class_name,\n",
    "                           f\"{d.x:.6f}\", f\"{d.y:.6f}\", f\"{d.w:.6f}\", f\"{d.h:.6f}\", f\"{d.confidence:.4f}\"])\n",
    "\n",
    "def save_wards(wards: List[Ward], path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['ward_id', 'class_id', 'class_name', 'x', 'y', 'frame_start', 'frame_end', 'detection_count', 'confidence_avg'])\n",
    "        for w in wards:\n",
    "            writer.writerow([w.ward_id, w.class_id, w.class_name, f\"{w.x:.6f}\", f\"{w.y:.6f}\",\n",
    "                           w.frame_start, w.frame_end, w.detection_count, f\"{w.confidence_avg:.4f}\"])\n",
    "\n",
    "print(\"関数定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-4: タイムライン統合関数\n",
    "\n",
    "def load_frame_timestamps(path: Path) -> Optional[Dict[int, int]]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    frame_to_time = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            frame = int(row['frame_number'])\n",
    "            time_ms = int(row['game_time_ms'])\n",
    "            if time_ms >= 0:\n",
    "                frame_to_time[frame] = time_ms\n",
    "    return frame_to_time if frame_to_time else None\n",
    "\n",
    "def timestamp_to_frame_from_map(ts: int, ft: Dict[int, int]) -> int:\n",
    "    best_frame, best_diff = 0, float('inf')\n",
    "    for frame, time_ms in ft.items():\n",
    "        diff = abs(time_ms - ts)\n",
    "        if diff < best_diff:\n",
    "            best_diff, best_frame = diff, frame\n",
    "    return best_frame\n",
    "\n",
    "def load_ward_events(timeline_path: Path, ft: Optional[Dict[int, int]], ms_per_frame: float) -> Tuple[List[TimelineWardEvent], List[TimelineWardEvent], dict]:\n",
    "    with open(timeline_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    placed, killed = [], []\n",
    "    stats = {\"total\": 0, \"filtered\": {\"creator_id_zero\": 0, \"undefined\": 0}, \"valid\": 0}\n",
    "    tid = 1\n",
    "\n",
    "    for frame in data.get(\"info\", {}).get(\"frames\", []):\n",
    "        for event in frame.get(\"events\", []):\n",
    "            if event.get(\"type\") == \"WARD_PLACED\":\n",
    "                stats[\"total\"] += 1\n",
    "                cid = event.get(\"creatorId\", 0)\n",
    "                ts = event.get(\"timestamp\", 0)\n",
    "                wt = event.get(\"wardType\", \"UNDEFINED\")\n",
    "                if cid == 0:\n",
    "                    stats[\"filtered\"][\"creator_id_zero\"] += 1\n",
    "                    continue\n",
    "                if wt == \"UNDEFINED\":\n",
    "                    stats[\"filtered\"][\"undefined\"] += 1\n",
    "                    continue\n",
    "                stats[\"valid\"] += 1\n",
    "                team = \"blue\" if 1 <= cid <= 5 else \"red\"\n",
    "                fe = timestamp_to_frame_from_map(ts, ft) if ft else int(ts / ms_per_frame)\n",
    "                placed.append(TimelineWardEvent(tid, \"PLACED\", ts, wt, cid, team, fe))\n",
    "                tid += 1\n",
    "            elif event.get(\"type\") == \"WARD_KILL\":\n",
    "                kid = event.get(\"killerId\", 0)\n",
    "                ts = event.get(\"timestamp\", 0)\n",
    "                wt = event.get(\"wardType\", \"UNDEFINED\")\n",
    "                fe = timestamp_to_frame_from_map(ts, ft) if ft else int(ts / ms_per_frame)\n",
    "                killed.append(TimelineWardEvent(0, \"KILLED\", ts, wt, kid, \"unknown\", fe))\n",
    "    return placed, killed, stats\n",
    "\n",
    "def filter_river_sights(wards: List[Ward], ft: Optional[Dict[int, int]], ms_per_frame: float) -> Tuple[List[Ward], int]:\n",
    "    filtered, removed = [], 0\n",
    "    for w in wards:\n",
    "        if not w.is_stealth_ward:\n",
    "            filtered.append(w)\n",
    "            continue\n",
    "        is_river = any(np.sqrt((w.x_pixel - rx)**2 + (w.y_pixel - ry)**2) <= RIVER_SIGHT_RADIUS for rx, ry in RIVER_SIGHT_POSITIONS)\n",
    "        if not is_river:\n",
    "            filtered.append(w)\n",
    "            continue\n",
    "        if ft:\n",
    "            duration = ft.get(w.frame_end, 0) - ft.get(w.frame_start, 0)\n",
    "        else:\n",
    "            duration = (w.frame_end - w.frame_start) * ms_per_frame\n",
    "        if RIVER_SIGHT_DURATION_MIN_MS <= duration < RIVER_SIGHT_DURATION_MAX_MS:\n",
    "            removed += 1\n",
    "        else:\n",
    "            filtered.append(w)\n",
    "    return filtered, removed\n",
    "\n",
    "def match_wards_hungarian(placed: List[TimelineWardEvent], killed: List[TimelineWardEvent],\n",
    "                          wards: List[Ward], ft: Optional[Dict[int, int]], ms_per_frame: float) -> List[MatchedWard]:\n",
    "    result = []\n",
    "    rid = 1\n",
    "\n",
    "    for wtype in [\"stealth\", \"control\"]:\n",
    "        events = [e for e in placed if (wtype == \"stealth\" and e.is_stealth_ward) or (wtype == \"control\" and e.is_control_ward)]\n",
    "        dets = [w for w in wards if not w.matched and ((wtype == \"stealth\" and w.is_stealth_ward) or (wtype == \"control\" and w.is_control_ward))]\n",
    "\n",
    "        if not events or not dets:\n",
    "            for e in events:\n",
    "                cn = \"control_ward\" if e.is_control_ward else \"stealth_ward\"\n",
    "                cn += \"_enemy\" if e.team == \"red\" else \"\"\n",
    "                result.append(MatchedWard(rid, e.timeline_ward_id, cn, e.ward_type, e.team, -1, -1, -1.0, -1.0,\n",
    "                              e.frame_expected, -1, 0.0, e.participant_id, e.timestamp, None, \"timeline_only\"))\n",
    "                rid += 1\n",
    "            continue\n",
    "\n",
    "        INF = 1e9\n",
    "        cost = np.full((len(events), len(dets)), INF)\n",
    "        for i, e in enumerate(events):\n",
    "            for j, w in enumerate(dets):\n",
    "                fd = w.frame_start - e.frame_expected\n",
    "                if fd < -FRAME_TOLERANCE or fd > FRAME_TOLERANCE * 3:\n",
    "                    continue\n",
    "                if w.team != e.team:\n",
    "                    continue\n",
    "                cost[i, j] = abs(fd) - w.confidence_avg * 10\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        matched_e, matched_d = set(), set()\n",
    "\n",
    "        for i, j in zip(row_ind, col_ind):\n",
    "            if cost[i, j] < INF:\n",
    "                e, w = events[i], dets[j]\n",
    "                w.matched = True\n",
    "                matched_e.add(i)\n",
    "                matched_d.add(j)\n",
    "                result.append(MatchedWard(rid, e.timeline_ward_id, w.class_name, e.ward_type, e.team,\n",
    "                              w.x_pixel, w.y_pixel, w.x, w.y, w.frame_start, w.frame_end, w.confidence_avg,\n",
    "                              e.participant_id, e.timestamp, None, \"matched\"))\n",
    "                rid += 1\n",
    "\n",
    "        for i, e in enumerate(events):\n",
    "            if i not in matched_e:\n",
    "                cn = \"control_ward\" if e.is_control_ward else \"stealth_ward\"\n",
    "                cn += \"_enemy\" if e.team == \"red\" else \"\"\n",
    "                result.append(MatchedWard(rid, e.timeline_ward_id, cn, e.ward_type, e.team, -1, -1, -1.0, -1.0,\n",
    "                              e.frame_expected, -1, 0.0, e.participant_id, e.timestamp, None, \"timeline_only\"))\n",
    "                rid += 1\n",
    "\n",
    "    for w in wards:\n",
    "        if not w.matched and w.confidence_avg >= MIN_CONFIDENCE_DETECTION_ONLY:\n",
    "            ts = ft.get(w.frame_start, 0) if ft else int(w.frame_start * ms_per_frame)\n",
    "            wt = \"CONTROL_WARD\" if w.is_control_ward else \"SIGHT_WARD\"\n",
    "            result.append(MatchedWard(rid, None, w.class_name, wt, w.team, w.x_pixel, w.y_pixel,\n",
    "                          w.x, w.y, w.frame_start, w.frame_end, w.confidence_avg, None, ts, None, \"detection_only\"))\n",
    "            rid += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def save_matched_wards(wards: List[MatchedWard], path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['ward_id', 'timeline_ward_id', 'class_name', 'ward_type', 'team',\n",
    "                        'x_pixel', 'y_pixel', 'x_normalized', 'y_normalized',\n",
    "                        'frame_start', 'frame_end', 'confidence_avg',\n",
    "                        'creator_id', 'timestamp_placed', 'timestamp_killed', 'match_status'])\n",
    "        for w in wards:\n",
    "            writer.writerow([w.ward_id, w.timeline_ward_id or '', w.class_name, w.ward_type, w.team,\n",
    "                           w.x_pixel if w.x_pixel >= 0 else '', w.y_pixel if w.y_pixel >= 0 else '',\n",
    "                           f\"{w.x_normalized:.6f}\" if w.x_normalized >= 0 else '',\n",
    "                           f\"{w.y_normalized:.6f}\" if w.y_normalized >= 0 else '',\n",
    "                           w.frame_start, w.frame_end if w.frame_end >= 0 else '',\n",
    "                           f\"{w.confidence_avg:.4f}\" if w.confidence_avg > 0 else '',\n",
    "                           w.creator_id or '', w.timestamp_placed or '', w.timestamp_killed or '', w.match_status])\n",
    "\n",
    "print(\"タイムライン統合関数定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-5: 全試合バッチ処理（YOLO推論 + クラスタリング + タイムライン統合）\n",
    "match_dirs = sorted(DATASET_DIR.glob(\"JP1-*\"))\n",
    "total_matches = len(match_dirs)\n",
    "\n",
    "print(f\"全{total_matches}試合の処理を開始\")\n",
    "print(f\"バッチサイズ: {BATCH_SIZE}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cumulative_matched = 0\n",
    "cumulative_total = 0\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, match_dir in enumerate(tqdm(match_dirs, desc=\"全体進捗\")):\n",
    "    match_id = match_dir.name\n",
    "    match_id_num = match_id.replace(\"JP1-\", \"\")\n",
    "\n",
    "    try:\n",
    "        # 1. YOLO推論\n",
    "        detections = run_inference(model, match_dir)\n",
    "        if not detections:\n",
    "            results.append({\"match\": match_id, \"detections\": 0, \"wards\": 0, \"matched\": 0})\n",
    "            continue\n",
    "\n",
    "        # 2. 保存\n",
    "        save_detections(detections, match_dir / \"detections_raw.csv\")\n",
    "\n",
    "        # 3. クラスタリング\n",
    "        wards = cluster_detections(detections)\n",
    "        save_wards(wards, match_dir / \"wards.csv\")\n",
    "\n",
    "        # 4. タイムライン統合\n",
    "        timeline_path = TIMELINE_DIR / f\"JP1_{match_id_num}.json\"\n",
    "        ft_path = match_dir / \"frame_timestamps.csv\"\n",
    "        ft = load_frame_timestamps(ft_path)\n",
    "        ms_per_frame = DEFAULT_MS_PER_FRAME\n",
    "\n",
    "        if timeline_path.exists():\n",
    "            placed, killed, stats = load_ward_events(timeline_path, ft, ms_per_frame)\n",
    "            wards_filtered, _ = filter_river_sights(wards, ft, ms_per_frame)\n",
    "            matched_wards = match_wards_hungarian(placed, killed, wards_filtered, ft, ms_per_frame)\n",
    "            save_matched_wards(matched_wards, match_dir / \"wards_matched.csv\")\n",
    "\n",
    "            matched_count = sum(1 for w in matched_wards if w.match_status == \"matched\")\n",
    "            total_count = stats[\"valid\"]\n",
    "        else:\n",
    "            matched_count, total_count = 0, 0\n",
    "\n",
    "        cumulative_matched += matched_count\n",
    "        cumulative_total += total_count\n",
    "        match_rate = cumulative_matched / cumulative_total * 100 if cumulative_total > 0 else 0\n",
    "\n",
    "        results.append({\"match\": match_id, \"detections\": len(detections), \"wards\": len(wards), \"matched\": matched_count})\n",
    "\n",
    "        if (i + 1) % 10 == 0 or i == total_matches - 1:\n",
    "            tqdm.write(f\"[{i+1}/{total_matches}] 累積マッチング率: {match_rate:.1f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"エラー [{match_id}]: {e}\")\n",
    "        results.append({\"match\": match_id, \"error\": str(e)})\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"処理完了\")\n",
    "print(\"=\"*60)\n",
    "print(f\"処理試合数: {len(results)}\")\n",
    "print(f\"総検出数: {sum(r.get('detections', 0) for r in results)}\")\n",
    "print(f\"総ward数: {sum(r.get('wards', 0) for r in results)}\")\n",
    "print(f\"マッチング率: {cumulative_matched}/{cumulative_total} ({match_rate:.1f}%)\")\n",
    "print(f\"総処理時間: {total_time/60:.1f}分\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "#cell-6: 結果確認\nprint(\"=== 処理結果サマリー ===\")\n\nmatch_results = []\nfor match_dir in match_dirs:\n    matched_csv = match_dir / \"wards_matched.csv\"\n    if matched_csv.exists():\n        df = pd.read_csv(matched_csv)\n        match_results.append({\n            \"match\": match_dir.name,\n            \"wards\": len(df),\n            \"matched\": len(df[df[\"match_status\"] == \"matched\"]) if \"match_status\" in df.columns else 0,\n        })\n\nresults_df = pd.DataFrame(match_results)\nprint(f\"\\n処理済み試合: {len(results_df)}\")\nprint(f\"総ward数: {results_df['wards'].sum()}\")\nprint(f\"マッチ済み: {results_df['matched'].sum()}\")\n\nif len(results_df) > 0 and results_df['wards'].sum() > 0:\n    final_match_rate = results_df['matched'].sum() / results_df['wards'].sum() * 100\n    print(f\"最終マッチング率: {final_match_rate:.1f}%\")\n\nresults_df.head(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "#cell-7: グリッド特徴量生成（ward_grid.npz）\n\n# === グリッド生成設定 ===\nGRID_SIZE = 32\nMINIMAP_SIZE = 512\nCELL_SIZE = MINIMAP_SIZE // GRID_SIZE\nNUM_PHASES = 3\n\nTIME_PHASES = [\n    (0, 10 * 60 * 1000),              # Phase 0: 0-10分\n    (10 * 60 * 1000, 20 * 60 * 1000),  # Phase 1: 10-20分\n    (20 * 60 * 1000, None),           # Phase 2: 20分以降\n]\n\nDEFAULT_DURATION_MS = {\n    \"YELLOW_TRINKET\": 90 * 1000,\n    \"SIGHT_WARD\": 90 * 1000,\n    \"CONTROL_WARD\": 180 * 1000,\n    \"BLUE_TRINKET\": 60 * 1000,\n}\n\ndef calculate_duration_ms(ward_type: str, timestamp_placed: int, timestamp_killed) -> int:\n    if timestamp_killed is not None and timestamp_killed != '':\n        return int(timestamp_killed) - timestamp_placed\n    return DEFAULT_DURATION_MS.get(ward_type, 90 * 1000)\n\ndef distribute_to_phases(timestamp_placed: int, duration_ms: int):\n    results = []\n    ward_start = timestamp_placed\n    ward_end = timestamp_placed + duration_ms\n    \n    for phase_idx, (phase_start, phase_end) in enumerate(TIME_PHASES):\n        if phase_end is None:\n            phase_end = float('inf')\n        overlap_start = max(ward_start, phase_start)\n        overlap_end = min(ward_end, phase_end)\n        if overlap_start < overlap_end:\n            duration_sec = (overlap_end - overlap_start) / 1000.0\n            results.append((phase_idx, duration_sec))\n    return results\n\ndef generate_ward_grid(wards_csv_path: Path) -> dict:\n    blue_grid = np.zeros((NUM_PHASES, GRID_SIZE, GRID_SIZE), dtype=np.float32)\n    red_grid = np.zeros((NUM_PHASES, GRID_SIZE, GRID_SIZE), dtype=np.float32)\n    match_id = wards_csv_path.parent.name\n    \n    with open(wards_csv_path, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if row.get('match_status') == 'timeline_only':\n                continue\n            \n            x_str, y_str = row.get('x_pixel', ''), row.get('y_pixel', '')\n            if not x_str or not y_str:\n                continue\n            \n            x_pixel, y_pixel = int(float(x_str)), int(float(y_str))\n            if not (0 <= x_pixel < MINIMAP_SIZE and 0 <= y_pixel < MINIMAP_SIZE):\n                continue\n            \n            team = row.get('team', '')\n            if team not in ('blue', 'red'):\n                continue\n            \n            ts_str = row.get('timestamp_placed', '')\n            if not ts_str:\n                continue\n            timestamp_placed = int(float(ts_str))\n            \n            timestamp_killed = row.get('timestamp_killed', '')\n            ward_type = row.get('ward_type', 'SIGHT_WARD')\n            \n            duration_ms = calculate_duration_ms(ward_type, timestamp_placed, timestamp_killed if timestamp_killed else None)\n            grid_x = min(x_pixel // CELL_SIZE, GRID_SIZE - 1)\n            grid_y = min(y_pixel // CELL_SIZE, GRID_SIZE - 1)\n            \n            for phase_idx, duration_sec in distribute_to_phases(timestamp_placed, duration_ms):\n                if team == 'blue':\n                    blue_grid[phase_idx, grid_y, grid_x] += duration_sec\n                else:\n                    red_grid[phase_idx, grid_y, grid_x] += duration_sec\n    \n    return {\"blue\": blue_grid, \"red\": red_grid, \"match_id\": match_id}\n\n# グリッド生成実行\nprint(\"グリッド特徴量生成を開始...\")\nprint(\"=\"*60)\n\ngrid_success = 0\ngrid_skip = 0\n\nfor match_dir in tqdm(match_dirs, desc=\"グリッド生成\"):\n    wards_csv = match_dir / \"wards_matched.csv\"\n    output_path = match_dir / \"ward_grid.npz\"\n    \n    if not wards_csv.exists():\n        grid_skip += 1\n        continue\n    \n    try:\n        grid_data = generate_ward_grid(wards_csv)\n        np.savez(output_path, blue=grid_data[\"blue\"], red=grid_data[\"red\"], match_id=grid_data[\"match_id\"])\n        grid_success += 1\n    except Exception as e:\n        tqdm.write(f\"エラー [{match_dir.name}]: {e}\")\n        grid_skip += 1\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"グリッド生成完了: {grid_success}試合\")\nprint(f\"スキップ: {grid_skip}試合\")"
  },
  {
   "cell_type": "code",
   "id": "7nilp1gb0e6",
   "source": "#cell-8: 処理完了\nprint(\"=\"*60)\nprint(\"Phase 3 完了（Colab版）\")\nprint(\"=\"*60)\nprint(f\"\\n出力ファイル（Google Driveに保存）:\")\nprint(f\"  - detections_raw.csv: 生の検出結果\")\nprint(f\"  - wards.csv: クラスタリング後ward情報\")\nprint(f\"  - wards_matched.csv: タイムライン統合済み\")\nprint(f\"  - ward_grid.npz: グリッド特徴量（32x32x3時間帯）\")\nprint(f\"\\n保存先: {DATASET_DIR}/JP1-*/\")\nprint(\"\\n次のステップ:\")\nprint(\"  -> 07_vision_score.ipynb でモデル学習・ヒートマップ可視化\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}